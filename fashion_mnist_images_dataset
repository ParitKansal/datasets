{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport csv\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\nfrom PIL import Image\n\n# Step 1: Load the FashionMNIST dataset\ntraining_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=True,\n    download=True,\n    transform=ToTensor()\n)\n\ntest_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=False,\n    download=True,\n    transform=ToTensor()\n)\n\n# Step 2: Define directories\noutput_dir = \"fashion_mnist_images\"\ntrain_dir = os.path.join(output_dir, \"train_images\")\ntest_dir = os.path.join(output_dir, \"test_images\")\nlabels_dir = os.path.join(output_dir, \"labels\")  # Directory for CSV files\n\n# Create directories if they don't exist\nos.makedirs(train_dir, exist_ok=True)\nos.makedirs(test_dir, exist_ok=True)\nos.makedirs(labels_dir, exist_ok=True)\n\n# Step 3: Function to save images and create a CSV file\ndef save_images_and_csv(dataset, image_directory, csv_directory, csv_filename):\n    \"\"\"\n    Save images from the dataset into the specified directory and create a CSV file\n    mapping filenames to their labels.\n\n    Args:\n        dataset: Dataset object containing images and labels.\n        image_directory: Directory to save the images.\n        csv_directory: Directory to save the CSV file.\n        csv_filename: Name of the CSV file.\n    \"\"\"\n    csv_path = os.path.join(csv_directory, csv_filename)\n    with open(csv_path, mode='w', newline='') as csv_file:\n        writer = csv.writer(csv_file)\n        writer.writerow([\"file_name\", \"label\"])  # Write header row\n\n        for index, (image, label) in enumerate(dataset):\n            # Convert tensor to PIL image\n            image = Image.fromarray((image.numpy().squeeze() * 255).astype('uint8'))\n            # Define file name\n            file_name = f\"{index}.png\"\n            # Save the image\n            image.save(os.path.join(image_directory, file_name))\n            # Write the file name and label to the CSV\n            writer.writerow([file_name, label])\n\n# Step 4: Save training data\nsave_images_and_csv(training_data, train_dir, labels_dir, \"train_labels.csv\")\n\n# Step 5: Save testing data\nsave_images_and_csv(test_data, test_dir, labels_dir, \"test_labels.csv\")\n\nprint(f\"Images saved in {output_dir}/train and {output_dir}/test.\")\nprint(f\"Labels saved in {output_dir}/labels.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-26T09:51:51.834027Z","iopub.execute_input":"2024-12-26T09:51:51.834432Z","iopub.status.idle":"2024-12-26T09:52:43.742126Z","shell.execute_reply.started":"2024-12-26T09:51:51.834393Z","shell.execute_reply":"2024-12-26T09:52:43.741009Z"}},"outputs":[{"name":"stdout","text":"Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 26421880/26421880 [00:03<00:00, 7863625.43it/s] \n","output_type":"stream"},{"name":"stdout","text":"Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 29515/29515 [00:00<00:00, 124746.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4422102/4422102 [00:01<00:00, 2309592.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5148/5148 [00:00<00:00, 8860187.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n\nImages saved in fashion_mnist_images/train and fashion_mnist_images/test.\nLabels saved in fashion_mnist_images/labels.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}